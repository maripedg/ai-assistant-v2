server:
  host: 0.0.0.0
  port: 8080
  cors:
    allow_origins: ["*"]
    allow_methods: ["*"]
    allow_headers: ["*"]

retrieval:
  mode: hybrid_prefer_db
  top_k: 12
  distance: dot_product
  score_kind: similarity
  docs_normalized: true
  # Mantén el comportamiento anterior: thresholds "planos"
  # NUEVO: selector de modo de puntuación y thresholds adicionales
  score_mode: normalized
  thresholds:
    low: 0.25
    high: 0.55
    raw_dot_low:  -0.50
    raw_dot_high: -0.20
    raw_cosine_low:  0.25
    raw_cosine_high: 0.55

  short_query:
    max_tokens: 3
    threshold_low: 0.20
    threshold_high: 0.45
    low: 0.28
    high: 0.58

  expansions:
    enabled: false
    terms:
      dbe:
        - digital business experience

  dedupe_by: doc_id

  legacy:
    store_metric: dot_product
    score_normalization: dot_to_sim01
    # legacy chunking: size 2000, overlap 100, separator '.'

  rag_if_any_hit: true

  # NUEVO: parámetros de ensamblado en modo híbrido
  hybrid:
    max_context_chars: 8000
    max_chunks: 3
    min_tokens_per_chunk: 0
    llm_enrichment: true
    cite_sources: true
    require_disclaimer_on_gaps: true
    # --- GATE: mínimos para permitir HYBRID ---
    min_similarity_for_hybrid: 0.60      # si max_similarity < 0.55 => forzar fallback
    min_chunks_for_hybrid: 1             # si usados < 2 => forzar fallback
    min_total_context_chars: 100        # si contexto < 1200 chars => forzar fallback
  explain: true
  llm_no_context:
    enabled: true
    precedence: ["exact_token", "regex_phrases"]
    exact_token:
      value: "NO_CONTEXT"
      case_insensitive: true
      strip_whitespace: true
    regex_phrases:
      case_insensitive: true
      patterns:
        - "\\bcontext (does not|doesn't) contain\\b"
        - "\\bno specific information\\b"
        - "\\bnot contain any information\\b"
        - "\\bdoes not mention\\b"
        - "\\bel contexto (no|no\\s+provee)\\b"
        - "\\bno hay información suficiente\\b"
        - "\\bno se encuentra información\\b"
    max_chars_for_exact_token: 64

embeddings:
  active_profile: legacy_profile   # default, can be switched to standard_profile later
  alias:
    name: MY_DEMO                  # DB view/synonym used by retrieval
    active_index: v1               # v1 -> MY_DEMO_v1, v2 -> MY_DEMO_v2
  profiles:
    legacy_profile:
      index_name: MY_DEMO_v1
      # Embedding input guardrails
      max_input_tokens: 512        # default 512 if missing
      on_token_limit: split        # split | truncate | skip
      token_estimator: auto        # auto | heuristic
      chunker:
        type: char
        separator: "."
        size: 2000
        overlap: 100
      distance_metric: dot_product
      input_types:
        documents: search_document
        queries:   search_query
      metadata:
        keep:
          - source
          - chunk_id
          - page
          - lang
    standard_profile:
      index_name: MY_DEMO_v2
      chunker:
        type: tokens
        size: 900
        overlap: 0.15
      distance_metric: cosine
      input_types:
        documents: search_document
        queries:   search_query
      metadata:
        keep:
          - source
          - title
          - page
          - lang
  batching:
    batch_size: 32
    workers: 4
    rate_limit_per_min: 300
  ocr:
    enabled: false
    engine: tesseract
  dedupe:
    by_hash: true
    hash_normalization: "lower_strip_ws"

prompts:
  no_context_token: "__NO_CONTEXT__"
  rag:
    system: |
      You are a technical assistant. Use ONLY the CONTEXT excerpts to answer.
      If the CONTEXT is insufficient, irrelevant, or does not contain the answer, output exactly __NO_CONTEXT__ and nothing else.
      If the user asks for a quote, quote ONLY text that appears verbatim in CONTEXT.
      Be concise. Cite source filenames in parentheses if you use them.
    max_output_tokens: 512

  hybrid:
    system: |
      You are a technical assistant. First, use the CONTEXT excerpts as primary evidence.
      If minor gaps exist, you MAY add brief bridging information, but never contradict the excerpts.
      If the CONTEXT is insufficient, irrelevant, or off-topic, output exactly __NO_CONTEXT__ and nothing else.
      If the user requests a quote, include at least one verbatim sentence from CONTEXT; if you cannot, return __NO_CONTEXT__.
      Prefer bullets/steps when the user asks for procedures. Cite source filenames where possible.
    max_output_tokens: 512
    
  fallback:
    system: |
      You are a helpful and knowledgeable assistant.
      Answer clearly and concisely using general knowledge only.
      Do NOT cite or refer to any document context.
      If the question is unrelated to your domain or cannot be answered reliably,
      explain the limitation politely and suggest how the user could rephrase or narrow the question.
      Keep the tone professional and neutral.
    max_output_tokens: 512

fallback:
  enabled: true
  policy: always_on_low_confidence

features:
  users_api: true
  feedback_api: true

storage:
  users:
    mode: db          # db | json
    json_path: data/users.json
  feedback:
    mode: db          # db | json
    json_path: data/feedback.json
  dual_write: false   # if true, writes go to both backends; reads follow `mode`

auth:
  mode: local         # local | sso | hybrid  (today: local)
  password_algo: bcrypt  # bcrypt | pbkdf2_sha256 (fallback)
  require_signup_approval: false

database:
  sqlalchemy_url: ""  # if empty, build from existing Oracle settings (user/pass/host/port/service)
  pool_min: 1
  pool_max: 5
  pool_timeout_seconds: 30
